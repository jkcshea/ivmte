% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mst.R
\name{ivmte}
\alias{ivmte}
\title{Instrumental Variables: Extrapolation by Marginal Treatment Effects}
\usage{
ivmte(data, target, late.from, late.to, late.X, genlate.lb, genlate.ub,
  target.weight0 = NULL, target.weight1 = NULL, target.knots0 = NULL,
  target.knots1 = NULL, m0, m1, uname = u, m1.ub, m0.ub, m1.lb, m0.lb,
  mte.ub, mte.lb, m0.dec, m0.inc, m1.dec, m1.inc, mte.dec, mte.inc, ivlike,
  components, subset, propensity, link = "logit", treat,
  lpsolver = NULL, obseq.tol = 0, initgrid.nx = 20,
  initgrid.nu = 20, audit.nx = 2500, audit.nu = 25,
  audit.add = 100, audit.max = 25, point = FALSE,
  point.eyeweight = FALSE, bootstraps = 0, bootstraps.m,
  bootstraps.replace = TRUE, levels = c(0.99, 0.95, 0.9),
  ci.type = "both", pvalue.tol = 1e-08, noisy = TRUE,
  smallreturnlist = FALSE, seed = 12345)
}
\arguments{
\item{data}{\code{data.frame} or \code{data.table} used to estimate
the treatment effects.}

\item{target}{character, target parameter to be
estimated. Currently function allows for ATE (\code{'ate'}),
ATT (\code{'att'}), ATU (\code{'atu'}), LATE (\code{'late'}),
and generalized LATE (\code{'genlate'}).}

\item{late.from}{a named vector, or a list, declaring the baseline
set of values of Z used to define the LATE. The name associated
with each value should be the name of the corresponding
variable.}

\item{late.to}{a named vector, or a list, declaring the comparison
set of values of Z used to define the LATE. The name associated
with each value should be the name of the corresponding
variable.}

\item{late.X}{a named vector, or a list, declaring the values at
which to condition on. The name associated with each value
should be the name of the corresponding variable.}

\item{genlate.lb}{lower bound value of unobservable \code{u} for
estimating the generalized LATE.}

\item{genlate.ub}{upper bound value of unobservable \code{u} for
estimating the generalized LATE.}

\item{target.weight0}{user-defined weight function for the control
group defining the target parameter. A list of functions can be
submitted if the weighting function is in fact a spline. The
arguments of the function should be variable names in
\code{data}. If the weight is constant across all observations,
then the user can instead submit the value of the weight
instead of a function.}

\item{target.weight1}{user-defined weight function for the treated
group defining the target parameter. See
\code{target.weight0} for details.}

\item{target.knots0}{user-defined set of functions defining the
knots associated with spline weights for the control group. The
arguments of the function should consist only of variable names
in \code{data}. If the knots are constant across all
observations, then the user can instead submit the vector of
knots instead of a function.}

\item{target.knots1}{user-defined set of functions defining the
knots associated with spline weights for the treated group. See
\code{target.knots0} for details.}

\item{m0}{one-sided formula for the marginal treatment response
function for the control group. Splines may also be
incorporated using the expression \code{uSpline}, e.g.
\code{uSpline(degree = 2, knots = c(0.4, 0.8), intercept =
TRUE)}. The \code{intercept} argument may be omitted, and is
set to \code{TRUE} by default.}

\item{m1}{one-sided formula for marginal treatment response
function for treated group. Splines can also be incorporated
using the expression "uSplines(degree, knots, intercept)". The
\code{intercept} argument may be omitted, and is set to
\code{TRUE} by default.}

\item{uname}{variable name for the unobservable used in declaring
the MTRs. The name can be provided with or without quotation
marks.}

\item{m1.ub}{numeric value for upper bound on MTR for the treated
group. By default, this will be set to the largest value of the
observed outcome in the estimation sample.}

\item{m0.ub}{numeric value for upper bound on MTR for the control
group. By default, this will be set to the largest value of the
observed outcome in the estimation sample.}

\item{m1.lb}{numeric value for lower bound on MTR for the treated
group. By default, this will be set to the smallest value of
the observed outcome in the estimation sample.}

\item{m0.lb}{numeric value for lower bound on MTR for the control
group. By default, this will be set to the smallest value of
the observed outcome in the estimation sample.}

\item{mte.ub}{numeric value for upper bound on treatment effect
parameter of interest.}

\item{mte.lb}{numeric value for lower bound on treatment effect
parameter of interest.}

\item{m0.dec}{logical, set to \code{FALSE} by default. Set equal to
\code{TRUE} if the MTR for the control group should be weakly
monotone decreasing.}

\item{m0.inc}{logical, set to \code{FALSE} by default. Set equal to
\code{TRUE} if the MTR for the control group should be weakly
monotone increasing.}

\item{m1.dec}{logical, set to \code{FALSE} by default. Set equal to
\code{TRUE} if the MTR for the treated group should be weakly
monotone decreasing.}

\item{m1.inc}{logical, set to \code{FALSE} by default. Set equal to
\code{TRUE} if the MTR for the treated group should be weakly
monotone increasing.}

\item{mte.dec}{logical, set to \code{FALSE} by default. Set equal
to \code{TRUE} if the MTE should be weakly monotone decreasing.}

\item{mte.inc}{logical, set to \code{FALSE} by default. Set equal
to \code{TRUE} if the MTE should be weakly monotone increasing.}

\item{ivlike}{formula or vector of formulas specifying the
regressions for the IV-like estimands. Which coefficients to
use to define the constraints determining the treatment effect
bounds (alternatively, the moments determining the treatment
effect point estimate) can be selected in the argument
\code{components}.}

\item{components}{a list of vectors of the terms in the regression
specifications to include in the set of IV-like estimands. No
terms should be in quotes. To select the intercept term,
include the name \code{intercept}. If the factorized
counterpart of a variable is included in the IV-like
specifications, e.g. \code{factor(x)} where \code{x = 1, 2, 3},
the user can select the coefficients for specific factors by
declaring the components \code{factor(x)-1, factor(x)-2,
factor(x)-3}. See \code{\link{l}} on how to input the
argument. If no components for a IV specification are given,
then all coefficients from that IV specification will be used
to define constraints in the partially identified case, or to
define moments in the point identified case.}

\item{subset}{a single subset condition or list of subset
conditions corresponding to each regression specified in
\code{ivlike}. The input must be logical. See \code{\link{l}}
on how to input the argument. If the user wishes to select
specific rows, construct a binary variable in the data set, and
set the condition to use only those observations for which the
binary variable is 1, e.g. the binary variable is \code{use},
and the subset condition is \code{use == 1}.}

\item{propensity}{formula or variable name corresponding to
propensity to take up treatment. If a formula is declared, then
the function estimates the propensity score according to the
formula and link specified in \code{link}. If a variable name
is declared, then the corresponding column in the data is taken
as the vector of propensity scores. A variable name can be
passed either as a string (e.g \code{propensity = 'p'}). , a
variable (e.g. \code{propensity = p}), or a one-sided formula
(e.g. \code{propensity = ~p}.}

\item{link}{character, name of link function to estimate propensity
score. Can be chosen from \code{'linear'}, \code{'probit'}, or
\code{'logit'}. Default is set to \code{'logit'}.}

\item{treat}{variable name for treatment indicator. The name can be
provided with or without quotation marks.}

\item{lpsolver}{character, name of the linear programming package
in R used to obtain the bounds on the treatment effect. The
function supports \code{'gurobi'}, \code{'rcplex'},
\code{'cplexapi'}, \code{'lpsolve'}, \code{'lpsolveapi'}.}

\item{obseq.tol}{tolerance for violation of observational
equivalence, set to 0 by default. Statistical noise may
prohibit the theoretical LP problem from being feasible. That
is, there may not exist a set of coefficients on the MTR that
are observationally equivalent with regard to the IV-like
regression coefficients. The function therefore first estimates
the minimum violation of observational equivalence. This is
reported in the output under the name 'minimum criterion'. The
constraints in the LP problem pertaining to observational
equivalence are then relaxed by the amount \code{minimum
criterion * (1 + obseq.tol)}. Set \code{obseq.tol} to a value
greater than 0 to allow for more conservative bounds.}

\item{initgrid.nx}{integer determining the number of evenly spread
points of the covariates used to form the initial grid for
imposing shape restrictions on the MTRs.}

\item{initgrid.nu}{integer determining the number of evenly spread
points in the interval [0, 1] of the unobservable \code{u} used
to form the initial grid for imposing shape restrictions on the
MTRs.}

\item{audit.nx}{integer determining the number of points on the
covariates space to audit in each iteration of the audit
procedure.}

\item{audit.nu}{integer determining the number of points in the
interval [0, 1], corresponding to space of unobservable
\code{u}, to audit in each iteration of the audit procedure.}

\item{audit.add}{maximum number of points to add to the initial
grid for imposing each kind of shape constraint. For example,
if there are 5 different kinds of shape constraints, there can
be at most \code{audit.add * 5} additional points added to the
initial grid.}

\item{audit.max}{maximum number of iterations in the audit
procedure.}

\item{point}{boolean, default set to \code{FALSE}. Set to
\code{TRUE} if it is believed that the treatment effects are
point identified. If set to \code{TRUE}, then a two-step GMM
procedure is implemented to estimate the treatment
effects. Shape constraints on the MTRs will be ignored under
point identification.}

\item{point.eyeweight}{boolean, default set to \code{FALSE}. Set to
\code{TRUE} if the GMM point estimate should use the identity
weighting matrix (i.e. one-step GMM).}

\item{bootstraps}{integer, default set to 0.}

\item{bootstraps.m}{integer, default set to size of data
set. Determines the size of the subsample drawn from the
original data set when performing inference via the
bootstrap. This option applies only to the case of constructing
confidence intervals for treatment effect bounds, i.e. it does
not apply when \code{point = TRUE}.}

\item{bootstraps.replace}{boolean, default set to \code{TRUE}. This
determines whether the resampling procedure used for inference
will sample with replacement.}

\item{levels}{vector of real numbers between 0 and 1. Values
correspond to the level of the confidence intervals constructed
via bootstrap.}

\item{ci.type}{character, default set to \code{'both'}. Set to
\code{'forward'} to construct the forward confidence interval
for the treatment effect bound. Set to \code{'backward'} to
construct the backward confidence interval for the treatment
effect bound. Set to \code{'both'} to construct both types of
confidence intervals.}

\item{pvalue.tol}{numeric, default set to 1e-08. The p-value under
the partially identified case is constructed by iteratively
adjusting the confidence level to find a confidence interval
that does not contain 0. When the adjustment of the confidence
level falls below \code{pvalue.tol}, no further iterations are
performed.}

\item{noisy}{boolean, default set to \code{TRUE}. If \code{TRUE},
then messages are provided throughout the estimation
procedure. Set to \code{FALSE} to suppress all messages,
e.g. when performing the bootstrap.}

\item{smallreturnlist}{boolean, default set to \code{FALSE}. Set to
\code{TRUE} to exclude large intermediary components
(i.e. propensity score model, LP model, bootstrap iterations)
from being included in the return list.}

\item{seed}{integer, the seed that determines the random grid in
the audit procedure.}
}
\value{
Returns a list of results from throughout the estimation
    procedure. This includes all IV-like estimands; the propensity
    score model; bounds on the treatment effect; the estimated
    expectations of each term in the MTRs; the components and
    results of the LP problem.
}
\description{
This function provides a general framework for using the marginal
treatment effect (MTE) to extrapolate. The model is the same binary
treatment instrumental variable (IV) model considered by
\href{https://doi.org/10.2307/2951620}{Imbens and Angrist (1994)}
and \href{https://doi.org/10.1111/j.1468-0262.2005.00594.x}{Heckman
and Vytlacil (2005)}. The framework on which this function is based
was developed by \href{https://doi.org/10.3982/ECTA15463}{Mogstad,
Santos and Torgovitsky (2018)}. See also the recent survey paper on
extrapolation in IV models by
\href{https://doi.org/10.1146/annurev-economics-101617-041813}{Mogstad
and Torgovitsky (2018)}. A detailed description of the module and
its features can be found in
\href{https://a-torgovitsky.github.io/shea-torgovitsky.pdf}{Shea
and Torgovitsky (2019)}.
}
\details{
The return list includes the following objects.
    \describe{
\item{sset}{a list of all the coefficient estimates and weights
    corresponding to each element in the S-set.}
\item{gstar}{a list containing the estimate of the weighted means
for each component in the MTRs. The weights are determined by the
target parameter declared in \code{target}, or the weights defined
by \code{target.weight1}, \code{target.knots1},
\code{target.weight0}, \code{target.knots0}.}
\item{gstar.weights}{a list containing the target weights used to
estimate \code{gstar}.}
\item{gstar.coef}{a list containing the coefficients on the treated
and control group MTRs.}
\item{propensity}{the propensity score model. If a variable is fed
to the \code{propensity} argument when calling \code{ivmte}, then
the returned object is a list containing the name of variable given by the
user, and the values of that variable used in estimation.}
\item{bounds}{a vector with the estimated lower and upper bounds of
the target treatment effect.}
\item{lpresult}{a list containing the LP model, and the full output
from solving the LP problem.}
\item{audit.grid}{the audit grid on which all shape constraints
were satisfied.}
\item{audit.count}{the number of audits required until there were
no more violations.}
\item{audit.minobseq}{the minimum criterion.}
\item{splinesdict}{a list including the specifications of each
spline declared in each MTR.}
}
}
\examples{
ivlikespecs <- c(ey ~ d | z,
                 ey ~ d | factor(z),
                 ey ~ d,
                 ey ~ d | factor(z))
jvec <- l(d, d, d, d)
svec <- l(, , , z \%in\% c(2, 4))

ivmte(ivlike = ivlikespecs,
      data = dtm,
      components = jvec,
      propensity = d ~ z,
      subset = svec,
      m0 = ~  u + I(u ^ 2),
      m1 = ~  u + I(u ^ 2),
      uname = u,
      target = "att",
      m0.dec = TRUE,
      m1.dec = TRUE,
      bootstraps = 0,
      lpsolver = "lpSolveAPI")

}
